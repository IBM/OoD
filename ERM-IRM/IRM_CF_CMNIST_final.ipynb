{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions to run this notebook\n",
    "\n",
    "In this notebook, we present the comparisons for CF-MNIST: Confounded colored MNIST.\n",
    "Run all the cells sequentially from top to bottom; we have commented the cells to help the reader."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import argparse\n",
    "import IPython.display as display\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "import cProfile\n",
    "from sklearn.model_selection import train_test_split\n",
    "import copy as cp\n",
    "from sklearn.model_selection import KFold\n",
    "from datetime import date\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_construct import * ## contains functions for constructing data \n",
    "from IRM_methods import *    ## contains IRM and ERM methods "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample complexity on CF-CMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tr1000\n",
      "trial 0\n",
      "60000\n",
      "(186,)\n",
      "(314,)\n",
      "(152,)\n",
      "(348,)\n",
      "(7004,)\n",
      "(2996,)\n",
      "WARNING:tensorflow:From /Users/kartikahuja/Desktop/Python_codes/aif360v1.env/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/100\n",
      "1000/1000 [==============================] - 0s 347us/sample - loss: 1.7836 - acc: 0.5790\n",
      "Epoch 2/100\n",
      "1000/1000 [==============================] - 0s 27us/sample - loss: 1.6669 - acc: 0.7150\n",
      "Epoch 3/100\n",
      "1000/1000 [==============================] - 0s 31us/sample - loss: 1.5929 - acc: 0.7610\n",
      "Epoch 4/100\n",
      "1000/1000 [==============================] - 0s 32us/sample - loss: 1.5299 - acc: 0.7800\n",
      "Epoch 5/100\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 1.4697 - acc: 0.8020\n",
      "Epoch 6/100\n",
      "1000/1000 [==============================] - 0s 32us/sample - loss: 1.4150 - acc: 0.8260\n",
      "Epoch 7/100\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 1.3681 - acc: 0.8610\n",
      "Epoch 8/100\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 1.3154 - acc: 0.8710\n",
      "Epoch 9/100\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 1.2731 - acc: 0.8760\n",
      "Epoch 10/100\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 1.2263 - acc: 0.8960\n",
      "Epoch 11/100\n",
      "1000/1000 [==============================] - 0s 33us/sample - loss: 1.1822 - acc: 0.9090\n",
      "Epoch 12/100\n",
      "1000/1000 [==============================] - 0s 34us/sample - loss: 1.1408 - acc: 0.9190\n",
      "Epoch 13/100\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 1.1009 - acc: 0.9210\n",
      "Epoch 14/100\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 1.0624 - acc: 0.9410\n",
      "Epoch 15/100\n",
      "1000/1000 [==============================] - 0s 34us/sample - loss: 1.0203 - acc: 0.9570\n",
      "Epoch 16/100\n",
      "1000/1000 [==============================] - 0s 34us/sample - loss: 0.9879 - acc: 0.9510\n",
      "Epoch 17/100\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 0.9525 - acc: 0.9610\n",
      "Epoch 18/100\n",
      "1000/1000 [==============================] - 0s 33us/sample - loss: 0.9196 - acc: 0.9670\n",
      "Epoch 19/100\n",
      "1000/1000 [==============================] - 0s 27us/sample - loss: 0.8954 - acc: 0.9710\n",
      "Epoch 20/100\n",
      "1000/1000 [==============================] - 0s 29us/sample - loss: 0.8576 - acc: 0.9810\n",
      "Epoch 21/100\n",
      "1000/1000 [==============================] - 0s 30us/sample - loss: 0.8325 - acc: 0.9870\n",
      "Epoch 22/100\n",
      "1000/1000 [==============================] - 0s 32us/sample - loss: 0.8081 - acc: 0.9880\n",
      "Epoch 23/100\n",
      "1000/1000 [==============================] - 0s 33us/sample - loss: 0.7804 - acc: 0.9910\n",
      "Epoch 24/100\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 0.7601 - acc: 0.9940\n",
      "Epoch 25/100\n",
      "1000/1000 [==============================] - 0s 33us/sample - loss: 0.7364 - acc: 0.9940\n",
      "Epoch 26/100\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.7162 - acc: 0.9950\n",
      "Epoch 27/100\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.7000 - acc: 0.9970\n",
      "Epoch 28/100\n",
      "1000/1000 [==============================] - 0s 34us/sample - loss: 0.6800 - acc: 0.9980\n",
      "Epoch 29/100\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.6634 - acc: 0.9970\n",
      "Epoch 30/100\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 0.6512 - acc: 0.9970\n",
      "Epoch 31/100\n",
      "1000/1000 [==============================] - 0s 33us/sample - loss: 0.6367 - acc: 0.9970\n",
      "Epoch 32/100\n",
      "1000/1000 [==============================] - 0s 32us/sample - loss: 0.6211 - acc: 0.9980\n",
      "Epoch 33/100\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 0.6087 - acc: 0.9980\n",
      "Epoch 34/100\n",
      "1000/1000 [==============================] - 0s 34us/sample - loss: 0.5946 - acc: 0.9980\n",
      "Epoch 35/100\n",
      "1000/1000 [==============================] - 0s 32us/sample - loss: 0.5831 - acc: 0.9990\n",
      "Epoch 36/100\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.5703 - acc: 0.9990\n",
      "Epoch 37/100\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.5602 - acc: 0.9990\n",
      "Epoch 38/100\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 0.5488 - acc: 0.9990\n",
      "Epoch 39/100\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.5394 - acc: 0.9990\n",
      "Epoch 40/100\n",
      "1000/1000 [==============================] - 0s 33us/sample - loss: 0.5293 - acc: 0.9990\n",
      "Epoch 41/100\n",
      "1000/1000 [==============================] - 0s 31us/sample - loss: 0.5202 - acc: 0.9990\n",
      "Epoch 42/100\n",
      "1000/1000 [==============================] - 0s 34us/sample - loss: 0.5102 - acc: 0.9980\n",
      "Epoch 43/100\n",
      "1000/1000 [==============================] - 0s 34us/sample - loss: 0.5015 - acc: 0.9990\n",
      "Epoch 44/100\n",
      "1000/1000 [==============================] - 0s 30us/sample - loss: 0.4928 - acc: 0.9990\n",
      "Epoch 45/100\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 0.4843 - acc: 0.9990\n",
      "Epoch 46/100\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.4759 - acc: 0.9990\n",
      "Epoch 47/100\n",
      "1000/1000 [==============================] - 0s 34us/sample - loss: 0.4684 - acc: 0.9990\n",
      "Epoch 48/100\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 0.4601 - acc: 0.9990\n",
      "Epoch 49/100\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.4528 - acc: 0.9990\n",
      "Epoch 50/100\n",
      "1000/1000 [==============================] - 0s 31us/sample - loss: 0.4459 - acc: 0.9980\n",
      "Epoch 51/100\n",
      "1000/1000 [==============================] - 0s 34us/sample - loss: 0.4385 - acc: 0.9980\n",
      "Epoch 52/100\n",
      "1000/1000 [==============================] - 0s 31us/sample - loss: 0.4310 - acc: 0.9990\n",
      "Epoch 53/100\n",
      "1000/1000 [==============================] - 0s 31us/sample - loss: 0.4247 - acc: 0.9990\n",
      "Epoch 54/100\n",
      "1000/1000 [==============================] - 0s 31us/sample - loss: 0.4174 - acc: 0.9990\n",
      "Epoch 55/100\n",
      "1000/1000 [==============================] - 0s 32us/sample - loss: 0.4111 - acc: 0.9990\n",
      "Epoch 56/100\n",
      "1000/1000 [==============================] - 0s 30us/sample - loss: 0.4045 - acc: 0.9990\n",
      "Epoch 57/100\n",
      "1000/1000 [==============================] - 0s 29us/sample - loss: 0.3982 - acc: 0.9990\n",
      "Epoch 58/100\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 0.3925 - acc: 0.9980\n",
      "Epoch 59/100\n",
      "1000/1000 [==============================] - 0s 29us/sample - loss: 0.3862 - acc: 0.9990\n",
      "Epoch 60/100\n",
      "1000/1000 [==============================] - 0s 30us/sample - loss: 0.3806 - acc: 0.9980\n",
      "Epoch 61/100\n",
      "1000/1000 [==============================] - 0s 29us/sample - loss: 0.3753 - acc: 0.9990\n",
      "Epoch 62/100\n",
      "1000/1000 [==============================] - 0s 28us/sample - loss: 0.3692 - acc: 0.9990\n",
      "Epoch 63/100\n",
      "1000/1000 [==============================] - 0s 30us/sample - loss: 0.3638 - acc: 0.9980\n",
      "Epoch 64/100\n",
      "1000/1000 [==============================] - 0s 29us/sample - loss: 0.3586 - acc: 0.9980\n",
      "Epoch 65/100\n",
      "1000/1000 [==============================] - 0s 31us/sample - loss: 0.3532 - acc: 0.9990\n",
      "Epoch 66/100\n",
      "1000/1000 [==============================] - 0s 31us/sample - loss: 0.3479 - acc: 0.9990\n",
      "Epoch 67/100\n",
      "1000/1000 [==============================] - 0s 29us/sample - loss: 0.3432 - acc: 0.9990\n",
      "Epoch 68/100\n",
      "1000/1000 [==============================] - 0s 34us/sample - loss: 0.3381 - acc: 0.9990\n",
      "Epoch 69/100\n",
      "1000/1000 [==============================] - 0s 28us/sample - loss: 0.3333 - acc: 0.9980\n",
      "Epoch 70/100\n",
      "1000/1000 [==============================] - 0s 28us/sample - loss: 0.3284 - acc: 0.9990\n",
      "Epoch 71/100\n",
      "1000/1000 [==============================] - 0s 31us/sample - loss: 0.3241 - acc: 0.9990\n",
      "Epoch 72/100\n",
      "1000/1000 [==============================] - 0s 31us/sample - loss: 0.3193 - acc: 0.9990\n",
      "Epoch 73/100\n",
      "1000/1000 [==============================] - 0s 29us/sample - loss: 0.3151 - acc: 0.9990\n",
      "Epoch 74/100\n",
      "1000/1000 [==============================] - 0s 29us/sample - loss: 0.3107 - acc: 0.9990\n",
      "Epoch 75/100\n",
      "1000/1000 [==============================] - 0s 29us/sample - loss: 0.3061 - acc: 0.9990\n",
      "Epoch 76/100\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 0.3021 - acc: 0.9990\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 31us/sample - loss: 0.2978 - acc: 0.9990\n",
      "Epoch 78/100\n",
      "1000/1000 [==============================] - 0s 34us/sample - loss: 0.2937 - acc: 0.9990\n",
      "Epoch 79/100\n",
      "1000/1000 [==============================] - 0s 31us/sample - loss: 0.2902 - acc: 0.9980\n",
      "Epoch 80/100\n",
      "1000/1000 [==============================] - 0s 33us/sample - loss: 0.2859 - acc: 0.9990\n",
      "Epoch 81/100\n",
      "1000/1000 [==============================] - 0s 31us/sample - loss: 0.2820 - acc: 0.9990\n",
      "Epoch 82/100\n",
      "1000/1000 [==============================] - 0s 32us/sample - loss: 0.2783 - acc: 0.9990\n",
      "Epoch 83/100\n",
      "1000/1000 [==============================] - 0s 33us/sample - loss: 0.2746 - acc: 0.9990\n",
      "Epoch 84/100\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 0.2710 - acc: 0.9990\n",
      "Epoch 85/100\n",
      "1000/1000 [==============================] - 0s 30us/sample - loss: 0.2674 - acc: 0.9990\n",
      "Epoch 86/100\n",
      "1000/1000 [==============================] - 0s 29us/sample - loss: 0.2639 - acc: 0.9990\n",
      "Epoch 87/100\n",
      "1000/1000 [==============================] - 0s 33us/sample - loss: 0.2610 - acc: 0.9980\n",
      "Epoch 88/100\n",
      "1000/1000 [==============================] - 0s 32us/sample - loss: 0.2573 - acc: 0.9990\n",
      "Epoch 89/100\n",
      "1000/1000 [==============================] - 0s 28us/sample - loss: 0.2539 - acc: 0.9990\n",
      "Epoch 90/100\n",
      "1000/1000 [==============================] - 0s 27us/sample - loss: 0.2508 - acc: 0.9990\n",
      "Epoch 91/100\n",
      "1000/1000 [==============================] - 0s 32us/sample - loss: 0.2479 - acc: 0.9980\n",
      "Epoch 92/100\n",
      "1000/1000 [==============================] - 0s 30us/sample - loss: 0.2453 - acc: 0.9980\n",
      "Epoch 93/100\n",
      "1000/1000 [==============================] - 0s 30us/sample - loss: 0.2415 - acc: 0.9990\n",
      "Epoch 94/100\n",
      "1000/1000 [==============================] - 0s 30us/sample - loss: 0.2382 - acc: 0.9990\n",
      "Epoch 95/100\n",
      "1000/1000 [==============================] - 0s 30us/sample - loss: 0.2363 - acc: 0.9990\n",
      "Epoch 96/100\n",
      "1000/1000 [==============================] - 0s 29us/sample - loss: 0.2329 - acc: 0.9990\n",
      "Epoch 97/100\n",
      "1000/1000 [==============================] - 0s 30us/sample - loss: 0.2303 - acc: 0.9990\n",
      "Epoch 98/100\n",
      "1000/1000 [==============================] - 0s 31us/sample - loss: 0.2270 - acc: 0.9990\n",
      "Epoch 99/100\n",
      "1000/1000 [==============================] - 0s 30us/sample - loss: 0.2248 - acc: 0.9980\n",
      "Epoch 100/100\n",
      "1000/1000 [==============================] - 0s 31us/sample - loss: 0.2215 - acc: 0.9990\n",
      "Training accuracy:0.9990000128746033\n",
      "Testing accuracy:0.34529998898506165\n",
      "Training accuracy:0.9987499713897705\n",
      "Validation accuracy:0.9987499713897705\n",
      "Testing accuracy:0.34119999408721924\n",
      "total time: 479.2949879169464\n",
      "tr5000\n",
      "trial 0\n",
      "60000\n",
      "(852,)\n",
      "(1648,)\n",
      "(771,)\n",
      "(1729,)\n",
      "(6977,)\n",
      "(3023,)\n",
      "Epoch 1/100\n",
      "5000/5000 [==============================] - 1s 127us/sample - loss: 1.6724 - acc: 0.6580\n",
      "Epoch 2/100\n",
      "5000/5000 [==============================] - 0s 53us/sample - loss: 1.4461 - acc: 0.7600\n",
      "Epoch 3/100\n",
      "5000/5000 [==============================] - 0s 44us/sample - loss: 1.2921 - acc: 0.7994\n",
      "Epoch 4/100\n",
      "5000/5000 [==============================] - 0s 41us/sample - loss: 1.1713 - acc: 0.8232\n",
      "Epoch 5/100\n",
      "5000/5000 [==============================] - 0s 42us/sample - loss: 1.0722 - acc: 0.8440\n",
      "Epoch 6/100\n",
      "5000/5000 [==============================] - 0s 42us/sample - loss: 0.9835 - acc: 0.8616\n",
      "Epoch 7/100\n",
      "5000/5000 [==============================] - 0s 42us/sample - loss: 0.9098 - acc: 0.8696\n",
      "Epoch 8/100\n",
      "5000/5000 [==============================] - 0s 42us/sample - loss: 0.8475 - acc: 0.8820\n",
      "Epoch 9/100\n",
      "5000/5000 [==============================] - 0s 46us/sample - loss: 0.8035 - acc: 0.8914\n",
      "Epoch 10/100\n",
      "5000/5000 [==============================] - 0s 46us/sample - loss: 0.7495 - acc: 0.8996\n",
      "Epoch 11/100\n",
      "5000/5000 [==============================] - 0s 45us/sample - loss: 0.7016 - acc: 0.9150\n",
      "Epoch 12/100\n",
      "5000/5000 [==============================] - 0s 45us/sample - loss: 0.6554 - acc: 0.9242\n",
      "Epoch 13/100\n",
      "5000/5000 [==============================] - 0s 44us/sample - loss: 0.6162 - acc: 0.9324\n",
      "Epoch 14/100\n",
      "5000/5000 [==============================] - 0s 49us/sample - loss: 0.5839 - acc: 0.9412\n",
      "Epoch 15/100\n",
      "5000/5000 [==============================] - 0s 47us/sample - loss: 0.5467 - acc: 0.9526\n",
      "Epoch 16/100\n",
      "5000/5000 [==============================] - 0s 45us/sample - loss: 0.5193 - acc: 0.9628\n",
      "Epoch 17/100\n",
      "5000/5000 [==============================] - 0s 40us/sample - loss: 0.4950 - acc: 0.9644\n",
      "Epoch 18/100\n",
      "5000/5000 [==============================] - 0s 49us/sample - loss: 0.4848 - acc: 0.9568\n",
      "Epoch 19/100\n",
      "5000/5000 [==============================] - 0s 43us/sample - loss: 0.4635 - acc: 0.9682\n",
      "Epoch 20/100\n",
      "5000/5000 [==============================] - 0s 38us/sample - loss: 0.4399 - acc: 0.9756\n",
      "Epoch 21/100\n",
      "5000/5000 [==============================] - 0s 42us/sample - loss: 0.4203 - acc: 0.9790\n",
      "Epoch 22/100\n",
      "5000/5000 [==============================] - 0s 46us/sample - loss: 0.3999 - acc: 0.9868\n",
      "Epoch 23/100\n",
      "5000/5000 [==============================] - 0s 43us/sample - loss: 0.3846 - acc: 0.9870\n",
      "Epoch 24/100\n",
      "5000/5000 [==============================] - 0s 46us/sample - loss: 0.3731 - acc: 0.9886\n",
      "Epoch 25/100\n",
      "5000/5000 [==============================] - 0s 45us/sample - loss: 0.3644 - acc: 0.9884\n",
      "Epoch 26/100\n",
      "5000/5000 [==============================] - 0s 48us/sample - loss: 0.3616 - acc: 0.9886\n",
      "Epoch 27/100\n",
      "5000/5000 [==============================] - 0s 49us/sample - loss: 0.3520 - acc: 0.9868\n",
      "Epoch 28/100\n",
      "5000/5000 [==============================] - 0s 53us/sample - loss: 0.3363 - acc: 0.9914\n",
      "Epoch 29/100\n",
      "5000/5000 [==============================] - 0s 54us/sample - loss: 0.3317 - acc: 0.9902\n",
      "Epoch 30/100\n",
      "5000/5000 [==============================] - 0s 45us/sample - loss: 0.3241 - acc: 0.9918\n",
      "Epoch 31/100\n",
      "5000/5000 [==============================] - 0s 43us/sample - loss: 0.3121 - acc: 0.9936\n",
      "Epoch 32/100\n",
      "5000/5000 [==============================] - 0s 42us/sample - loss: 0.3027 - acc: 0.9934\n",
      "Epoch 33/100\n",
      "5000/5000 [==============================] - 0s 41us/sample - loss: 0.2959 - acc: 0.9940\n",
      "Epoch 34/100\n",
      "5000/5000 [==============================] - 0s 40us/sample - loss: 0.2902 - acc: 0.9930\n",
      "Epoch 35/100\n",
      "5000/5000 [==============================] - 0s 42us/sample - loss: 0.2870 - acc: 0.9926\n",
      "Epoch 36/100\n",
      "5000/5000 [==============================] - 0s 45us/sample - loss: 0.2810 - acc: 0.9946\n",
      "Epoch 37/100\n",
      "5000/5000 [==============================] - 0s 43us/sample - loss: 0.2768 - acc: 0.9942\n",
      "Epoch 38/100\n",
      "5000/5000 [==============================] - 0s 40us/sample - loss: 0.2701 - acc: 0.9934\n",
      "Epoch 39/100\n",
      "5000/5000 [==============================] - 0s 43us/sample - loss: 0.2632 - acc: 0.9930\n",
      "Epoch 40/100\n",
      "5000/5000 [==============================] - 0s 43us/sample - loss: 0.2590 - acc: 0.9936\n",
      "Epoch 41/100\n",
      "5000/5000 [==============================] - 0s 43us/sample - loss: 0.2534 - acc: 0.9950\n",
      "Epoch 42/100\n",
      "5000/5000 [==============================] - 0s 47us/sample - loss: 0.2487 - acc: 0.9944\n",
      "Epoch 43/100\n",
      "5000/5000 [==============================] - 0s 42us/sample - loss: 0.2460 - acc: 0.9944\n",
      "Epoch 44/100\n",
      "5000/5000 [==============================] - 0s 43us/sample - loss: 0.2442 - acc: 0.9940\n",
      "Epoch 45/100\n",
      "5000/5000 [==============================] - 0s 43us/sample - loss: 0.2434 - acc: 0.9922\n",
      "Epoch 46/100\n",
      "5000/5000 [==============================] - 0s 41us/sample - loss: 0.2402 - acc: 0.9934\n",
      "Epoch 47/100\n",
      "5000/5000 [==============================] - 0s 46us/sample - loss: 0.2358 - acc: 0.9944\n",
      "Epoch 48/100\n",
      "5000/5000 [==============================] - 0s 42us/sample - loss: 0.2291 - acc: 0.9948\n",
      "Epoch 49/100\n",
      "5000/5000 [==============================] - 0s 45us/sample - loss: 0.2217 - acc: 0.9952\n",
      "Epoch 50/100\n",
      "5000/5000 [==============================] - 0s 45us/sample - loss: 0.2183 - acc: 0.9936\n",
      "Epoch 51/100\n",
      "5000/5000 [==============================] - 0s 50us/sample - loss: 0.2125 - acc: 0.9946\n",
      "Epoch 52/100\n",
      "5000/5000 [==============================] - 0s 43us/sample - loss: 0.2105 - acc: 0.9944\n",
      "Epoch 53/100\n",
      "5000/5000 [==============================] - 0s 44us/sample - loss: 0.2066 - acc: 0.9946\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 0s 53us/sample - loss: 0.2038 - acc: 0.9956\n",
      "Epoch 55/100\n",
      "5000/5000 [==============================] - 0s 51us/sample - loss: 0.2036 - acc: 0.9940\n",
      "Epoch 56/100\n",
      "5000/5000 [==============================] - 0s 49us/sample - loss: 0.1999 - acc: 0.9950\n",
      "Epoch 57/100\n",
      "5000/5000 [==============================] - 0s 41us/sample - loss: 0.1969 - acc: 0.9942\n",
      "Epoch 58/100\n",
      "5000/5000 [==============================] - 0s 47us/sample - loss: 0.1962 - acc: 0.9940\n",
      "Epoch 59/100\n",
      "5000/5000 [==============================] - 0s 41us/sample - loss: 0.1885 - acc: 0.9954\n",
      "Epoch 60/100\n",
      "5000/5000 [==============================] - 0s 43us/sample - loss: 0.1851 - acc: 0.9952\n",
      "Epoch 61/100\n",
      "5000/5000 [==============================] - 0s 43us/sample - loss: 0.1883 - acc: 0.9948\n",
      "Epoch 62/100\n",
      "5000/5000 [==============================] - 0s 43us/sample - loss: 0.1889 - acc: 0.9936\n",
      "Epoch 63/100\n",
      "5000/5000 [==============================] - 0s 41us/sample - loss: 0.1810 - acc: 0.9952\n",
      "Epoch 64/100\n",
      "5000/5000 [==============================] - 0s 45us/sample - loss: 0.1747 - acc: 0.9954\n",
      "Epoch 65/100\n",
      "5000/5000 [==============================] - 0s 43us/sample - loss: 0.1749 - acc: 0.9950\n",
      "Epoch 66/100\n",
      "5000/5000 [==============================] - 0s 45us/sample - loss: 0.1705 - acc: 0.9954\n",
      "Epoch 67/100\n",
      "5000/5000 [==============================] - 0s 43us/sample - loss: 0.1679 - acc: 0.9954\n",
      "Epoch 68/100\n",
      "5000/5000 [==============================] - 0s 44us/sample - loss: 0.1656 - acc: 0.9954\n",
      "Epoch 69/100\n",
      "5000/5000 [==============================] - 0s 42us/sample - loss: 0.1644 - acc: 0.9948\n",
      "Epoch 70/100\n",
      "5000/5000 [==============================] - 0s 46us/sample - loss: 0.1628 - acc: 0.9954\n",
      "Epoch 71/100\n",
      "5000/5000 [==============================] - 0s 47us/sample - loss: 0.1614 - acc: 0.9932\n",
      "Epoch 72/100\n",
      "5000/5000 [==============================] - 0s 43us/sample - loss: 0.1568 - acc: 0.9950\n",
      "Epoch 73/100\n",
      "5000/5000 [==============================] - 0s 44us/sample - loss: 0.1565 - acc: 0.9952\n",
      "Epoch 74/100\n",
      "5000/5000 [==============================] - 0s 41us/sample - loss: 0.1557 - acc: 0.9944\n",
      "Epoch 75/100\n",
      "5000/5000 [==============================] - 0s 42us/sample - loss: 0.1559 - acc: 0.9940\n",
      "Epoch 76/100\n",
      "5000/5000 [==============================] - 0s 47us/sample - loss: 0.1517 - acc: 0.9948\n",
      "Epoch 77/100\n",
      "5000/5000 [==============================] - 0s 44us/sample - loss: 0.1493 - acc: 0.9950\n",
      "Epoch 78/100\n",
      "5000/5000 [==============================] - 0s 45us/sample - loss: 0.1499 - acc: 0.9950\n",
      "Epoch 79/100\n",
      "5000/5000 [==============================] - 0s 44us/sample - loss: 0.1452 - acc: 0.9952\n",
      "Epoch 80/100\n",
      "5000/5000 [==============================] - 0s 43us/sample - loss: 0.1455 - acc: 0.9950\n",
      "Epoch 81/100\n",
      "5000/5000 [==============================] - 0s 43us/sample - loss: 0.1413 - acc: 0.9948\n",
      "Epoch 82/100\n",
      "5000/5000 [==============================] - 0s 43us/sample - loss: 0.1399 - acc: 0.9948\n",
      "Epoch 83/100\n",
      "5000/5000 [==============================] - 0s 45us/sample - loss: 0.1424 - acc: 0.9942\n",
      "Epoch 84/100\n",
      "5000/5000 [==============================] - 0s 47us/sample - loss: 0.1407 - acc: 0.9950\n",
      "Epoch 85/100\n",
      "5000/5000 [==============================] - 0s 41us/sample - loss: 0.1395 - acc: 0.9946\n",
      "Epoch 86/100\n",
      "5000/5000 [==============================] - 0s 44us/sample - loss: 0.1360 - acc: 0.9956\n",
      "Epoch 87/100\n",
      "5000/5000 [==============================] - 0s 49us/sample - loss: 0.1366 - acc: 0.9952\n",
      "Epoch 88/100\n",
      "5000/5000 [==============================] - 0s 51us/sample - loss: 0.1339 - acc: 0.9946\n",
      "Epoch 89/100\n",
      "5000/5000 [==============================] - 0s 45us/sample - loss: 0.1425 - acc: 0.9918\n",
      "Epoch 90/100\n",
      "5000/5000 [==============================] - 0s 46us/sample - loss: 0.1390 - acc: 0.9938\n",
      "Epoch 91/100\n",
      "5000/5000 [==============================] - 0s 48us/sample - loss: 0.1378 - acc: 0.9936\n",
      "Epoch 92/100\n",
      "5000/5000 [==============================] - 0s 49us/sample - loss: 0.1312 - acc: 0.9946\n",
      "Epoch 93/100\n",
      "5000/5000 [==============================] - 0s 42us/sample - loss: 0.1289 - acc: 0.9950\n",
      "Epoch 94/100\n",
      "5000/5000 [==============================] - 0s 43us/sample - loss: 0.1482 - acc: 0.9872\n",
      "Epoch 95/100\n",
      "5000/5000 [==============================] - 0s 48us/sample - loss: 0.1528 - acc: 0.9848\n",
      "Epoch 96/100\n",
      "5000/5000 [==============================] - 0s 47us/sample - loss: 0.1407 - acc: 0.9916\n",
      "Epoch 97/100\n",
      "5000/5000 [==============================] - 0s 49us/sample - loss: 0.1384 - acc: 0.9916\n",
      "Epoch 98/100\n",
      "5000/5000 [==============================] - 0s 45us/sample - loss: 0.1368 - acc: 0.9926\n",
      "Epoch 99/100\n",
      "5000/5000 [==============================] - 0s 46us/sample - loss: 0.1286 - acc: 0.9944\n",
      "Epoch 100/100\n",
      "5000/5000 [==============================] - 0s 44us/sample - loss: 0.1253 - acc: 0.9940\n",
      "Training accuracy:0.9962000250816345\n",
      "Testing accuracy:0.3402000069618225\n",
      "Training accuracy:0.952750027179718\n",
      "Validation accuracy:0.952750027179718\n",
      "Testing accuracy:0.30709999799728394\n",
      "total time: 856.5081472396851\n",
      "tr10000\n",
      "trial 0\n",
      "60000\n",
      "(1742,)\n",
      "(3258,)\n",
      "(1485,)\n",
      "(3515,)\n",
      "(7045,)\n",
      "(2955,)\n",
      "Epoch 1/100\n",
      "10000/10000 [==============================] - 1s 106us/sample - loss: 1.5989 - acc: 0.6689\n",
      "Epoch 2/100\n",
      "10000/10000 [==============================] - 1s 50us/sample - loss: 1.2847 - acc: 0.7723\n",
      "Epoch 3/100\n",
      "10000/10000 [==============================] - 1s 52us/sample - loss: 1.0973 - acc: 0.8037\n",
      "Epoch 4/100\n",
      "10000/10000 [==============================] - 1s 68us/sample - loss: 0.9606 - acc: 0.8285\n",
      "Epoch 5/100\n",
      "10000/10000 [==============================] - 1s 56us/sample - loss: 0.8676 - acc: 0.8407\n",
      "Epoch 6/100\n",
      "10000/10000 [==============================] - 1s 66us/sample - loss: 0.7922 - acc: 0.8506\n",
      "Epoch 7/100\n",
      "10000/10000 [==============================] - 1s 59us/sample - loss: 0.7408 - acc: 0.8564\n",
      "Epoch 8/100\n",
      "10000/10000 [==============================] - 1s 57us/sample - loss: 0.6866 - acc: 0.8671\n",
      "Epoch 9/100\n",
      "10000/10000 [==============================] - 1s 57us/sample - loss: 0.6531 - acc: 0.8731\n",
      "Epoch 10/100\n",
      "10000/10000 [==============================] - 1s 58us/sample - loss: 0.6054 - acc: 0.8886\n",
      "Epoch 11/100\n",
      "10000/10000 [==============================] - 1s 58us/sample - loss: 0.5741 - acc: 0.8932\n",
      "Epoch 12/100\n",
      "10000/10000 [==============================] - 1s 58us/sample - loss: 0.5503 - acc: 0.8932\n",
      "Epoch 13/100\n",
      "10000/10000 [==============================] - 1s 55us/sample - loss: 0.5069 - acc: 0.9137\n",
      "Epoch 14/100\n",
      "10000/10000 [==============================] - 1s 58us/sample - loss: 0.4825 - acc: 0.9167\n",
      "Epoch 15/100\n",
      "10000/10000 [==============================] - 1s 56us/sample - loss: 0.4535 - acc: 0.9286\n",
      "Epoch 16/100\n",
      "10000/10000 [==============================] - 1s 56us/sample - loss: 0.4342 - acc: 0.9330\n",
      "Epoch 17/100\n",
      "10000/10000 [==============================] - 1s 60us/sample - loss: 0.4238 - acc: 0.9334\n",
      "Epoch 18/100\n",
      "10000/10000 [==============================] - 1s 62us/sample - loss: 0.4072 - acc: 0.9379\n",
      "Epoch 19/100\n",
      "10000/10000 [==============================] - 1s 59us/sample - loss: 0.3667 - acc: 0.9550\n",
      "Epoch 20/100\n",
      "10000/10000 [==============================] - 1s 59us/sample - loss: 0.3512 - acc: 0.9562\n",
      "Epoch 21/100\n",
      "10000/10000 [==============================] - 1s 53us/sample - loss: 0.3335 - acc: 0.9631\n",
      "Epoch 22/100\n",
      "10000/10000 [==============================] - 1s 62us/sample - loss: 0.3194 - acc: 0.9641\n",
      "Epoch 23/100\n",
      "10000/10000 [==============================] - 1s 60us/sample - loss: 0.3207 - acc: 0.9616\n",
      "Epoch 24/100\n",
      "10000/10000 [==============================] - 1s 68us/sample - loss: 0.3133 - acc: 0.9628\n",
      "Epoch 25/100\n",
      "10000/10000 [==============================] - 1s 56us/sample - loss: 0.2953 - acc: 0.9680\n",
      "Epoch 26/100\n",
      "10000/10000 [==============================] - 1s 56us/sample - loss: 0.2892 - acc: 0.9684\n",
      "Epoch 27/100\n",
      "10000/10000 [==============================] - 1s 59us/sample - loss: 0.2709 - acc: 0.9744\n",
      "Epoch 28/100\n",
      "10000/10000 [==============================] - 1s 55us/sample - loss: 0.2550 - acc: 0.9790\n",
      "Epoch 29/100\n",
      "10000/10000 [==============================] - 1s 63us/sample - loss: 0.2523 - acc: 0.9779\n",
      "Epoch 30/100\n",
      "10000/10000 [==============================] - 1s 58us/sample - loss: 0.2526 - acc: 0.9772\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 55us/sample - loss: 0.2374 - acc: 0.9815\n",
      "Epoch 32/100\n",
      "10000/10000 [==============================] - 1s 67us/sample - loss: 0.2352 - acc: 0.9815\n",
      "Epoch 33/100\n",
      "10000/10000 [==============================] - 1s 58us/sample - loss: 0.2240 - acc: 0.9837\n",
      "Epoch 34/100\n",
      "10000/10000 [==============================] - 1s 62us/sample - loss: 0.2257 - acc: 0.9815\n",
      "Epoch 35/100\n",
      "10000/10000 [==============================] - 1s 59us/sample - loss: 0.2237 - acc: 0.9814\n",
      "Epoch 36/100\n",
      "10000/10000 [==============================] - 1s 62us/sample - loss: 0.2122 - acc: 0.9848\n",
      "Epoch 37/100\n",
      "10000/10000 [==============================] - 1s 63us/sample - loss: 0.2083 - acc: 0.9843\n",
      "Epoch 38/100\n",
      "10000/10000 [==============================] - 1s 59us/sample - loss: 0.2111 - acc: 0.9827\n",
      "Epoch 39/100\n",
      "10000/10000 [==============================] - 1s 59us/sample - loss: 0.2017 - acc: 0.9846\n",
      "Epoch 40/100\n",
      "10000/10000 [==============================] - 1s 63us/sample - loss: 0.1957 - acc: 0.9852\n",
      "Epoch 41/100\n",
      "10000/10000 [==============================] - 1s 60us/sample - loss: 0.2012 - acc: 0.9815\n",
      "Epoch 42/100\n",
      "10000/10000 [==============================] - 1s 65us/sample - loss: 0.1993 - acc: 0.9828\n",
      "Epoch 43/100\n",
      "10000/10000 [==============================] - 1s 63us/sample - loss: 0.1936 - acc: 0.9847\n",
      "Epoch 44/100\n",
      "10000/10000 [==============================] - 1s 65us/sample - loss: 0.1883 - acc: 0.9841\n",
      "Epoch 45/100\n",
      "10000/10000 [==============================] - 1s 66us/sample - loss: 0.1799 - acc: 0.9862\n",
      "Epoch 46/100\n",
      "10000/10000 [==============================] - 1s 71us/sample - loss: 0.1759 - acc: 0.9871\n",
      "Epoch 47/100\n",
      "10000/10000 [==============================] - 1s 64us/sample - loss: 0.1762 - acc: 0.9866\n",
      "Epoch 48/100\n",
      "10000/10000 [==============================] - 1s 67us/sample - loss: 0.1697 - acc: 0.9868\n",
      "Epoch 49/100\n",
      "10000/10000 [==============================] - 1s 68us/sample - loss: 0.1722 - acc: 0.9863\n",
      "Epoch 50/100\n",
      "10000/10000 [==============================] - 1s 69us/sample - loss: 0.1714 - acc: 0.9850\n",
      "Epoch 51/100\n",
      "10000/10000 [==============================] - 1s 72us/sample - loss: 0.1700 - acc: 0.9853\n",
      "Epoch 52/100\n",
      "10000/10000 [==============================] - 1s 60us/sample - loss: 0.1643 - acc: 0.9865\n",
      "Epoch 53/100\n",
      "10000/10000 [==============================] - 1s 69us/sample - loss: 0.1658 - acc: 0.9855\n",
      "Epoch 54/100\n",
      "10000/10000 [==============================] - 1s 64us/sample - loss: 0.1659 - acc: 0.9854\n",
      "Epoch 55/100\n",
      "10000/10000 [==============================] - 1s 67us/sample - loss: 0.1608 - acc: 0.9863\n",
      "Epoch 56/100\n",
      "10000/10000 [==============================] - 1s 71us/sample - loss: 0.1600 - acc: 0.9858\n",
      "Epoch 57/100\n",
      "10000/10000 [==============================] - 1s 69us/sample - loss: 0.1542 - acc: 0.9870\n",
      "Epoch 58/100\n",
      "10000/10000 [==============================] - 1s 66us/sample - loss: 0.1530 - acc: 0.9868\n",
      "Epoch 59/100\n",
      "10000/10000 [==============================] - 1s 65us/sample - loss: 0.1531 - acc: 0.9876\n",
      "Epoch 60/100\n",
      "10000/10000 [==============================] - 1s 62us/sample - loss: 0.1515 - acc: 0.98660s - loss: 0.1498 - acc: 0\n",
      "Epoch 61/100\n",
      "10000/10000 [==============================] - 1s 62us/sample - loss: 0.1476 - acc: 0.9877\n",
      "Epoch 62/100\n",
      "10000/10000 [==============================] - 1s 67us/sample - loss: 0.1492 - acc: 0.9871\n",
      "Epoch 63/100\n",
      "10000/10000 [==============================] - 1s 66us/sample - loss: 0.1473 - acc: 0.9865\n",
      "Epoch 64/100\n",
      "10000/10000 [==============================] - 1s 66us/sample - loss: 0.1578 - acc: 0.9823\n",
      "Epoch 65/100\n",
      "10000/10000 [==============================] - 1s 60us/sample - loss: 0.1621 - acc: 0.9814\n",
      "Epoch 66/100\n",
      "10000/10000 [==============================] - 1s 67us/sample - loss: 0.1482 - acc: 0.9850\n",
      "Epoch 67/100\n",
      "10000/10000 [==============================] - 1s 58us/sample - loss: 0.1485 - acc: 0.9865\n",
      "Epoch 68/100\n",
      "10000/10000 [==============================] - 1s 61us/sample - loss: 0.1411 - acc: 0.9871\n",
      "Epoch 69/100\n",
      "10000/10000 [==============================] - 1s 61us/sample - loss: 0.1408 - acc: 0.9873\n",
      "Epoch 70/100\n",
      "10000/10000 [==============================] - 1s 55us/sample - loss: 0.1574 - acc: 0.9793\n",
      "Epoch 71/100\n",
      "10000/10000 [==============================] - 1s 57us/sample - loss: 0.1541 - acc: 0.9796\n",
      "Epoch 72/100\n",
      "10000/10000 [==============================] - 1s 60us/sample - loss: 0.1487 - acc: 0.9849\n",
      "Epoch 73/100\n",
      "10000/10000 [==============================] - 1s 61us/sample - loss: 0.1400 - acc: 0.9869\n",
      "Epoch 74/100\n",
      "10000/10000 [==============================] - 1s 61us/sample - loss: 0.1357 - acc: 0.9869\n",
      "Epoch 75/100\n",
      "10000/10000 [==============================] - 1s 71us/sample - loss: 0.1312 - acc: 0.9873\n",
      "Epoch 76/100\n",
      "10000/10000 [==============================] - 1s 71us/sample - loss: 0.1306 - acc: 0.9884\n",
      "Epoch 77/100\n",
      "10000/10000 [==============================] - 1s 65us/sample - loss: 0.1294 - acc: 0.9875\n",
      "Epoch 78/100\n",
      "10000/10000 [==============================] - 1s 65us/sample - loss: 0.1270 - acc: 0.9874\n",
      "Epoch 79/100\n",
      "10000/10000 [==============================] - 1s 70us/sample - loss: 0.1336 - acc: 0.9844\n",
      "Epoch 80/100\n",
      "10000/10000 [==============================] - 1s 62us/sample - loss: 0.1364 - acc: 0.9862\n",
      "Epoch 81/100\n",
      "10000/10000 [==============================] - 1s 62us/sample - loss: 0.1308 - acc: 0.9880\n",
      "Epoch 82/100\n",
      "10000/10000 [==============================] - 1s 59us/sample - loss: 0.1241 - acc: 0.9876\n",
      "Epoch 83/100\n",
      "10000/10000 [==============================] - 1s 58us/sample - loss: 0.1268 - acc: 0.9868\n",
      "Epoch 84/100\n",
      "10000/10000 [==============================] - 1s 66us/sample - loss: 0.1297 - acc: 0.9869\n",
      "Epoch 85/100\n",
      "10000/10000 [==============================] - 1s 68us/sample - loss: 0.1307 - acc: 0.9868\n",
      "Epoch 86/100\n",
      "10000/10000 [==============================] - 1s 61us/sample - loss: 0.1403 - acc: 0.9817\n",
      "Epoch 87/100\n",
      "10000/10000 [==============================] - 1s 67us/sample - loss: 0.1363 - acc: 0.9845\n",
      "Epoch 88/100\n",
      "10000/10000 [==============================] - 1s 73us/sample - loss: 0.1246 - acc: 0.9868\n",
      "Epoch 89/100\n",
      "10000/10000 [==============================] - 1s 65us/sample - loss: 0.1265 - acc: 0.9869\n",
      "Epoch 90/100\n",
      "10000/10000 [==============================] - 1s 74us/sample - loss: 0.1300 - acc: 0.9851\n",
      "Epoch 91/100\n",
      "10000/10000 [==============================] - 1s 65us/sample - loss: 0.1240 - acc: 0.9876\n",
      "Epoch 92/100\n",
      "10000/10000 [==============================] - 1s 68us/sample - loss: 0.1179 - acc: 0.9894\n",
      "Epoch 93/100\n",
      "10000/10000 [==============================] - 1s 71us/sample - loss: 0.1206 - acc: 0.9866\n",
      "Epoch 94/100\n",
      "10000/10000 [==============================] - ETA: 0s - loss: 0.1168 - acc: 0.988 - 1s 56us/sample - loss: 0.1204 - acc: 0.9874\n",
      "Epoch 95/100\n",
      "10000/10000 [==============================] - 1s 61us/sample - loss: 0.1182 - acc: 0.9884\n",
      "Epoch 96/100\n",
      "10000/10000 [==============================] - 1s 65us/sample - loss: 0.1215 - acc: 0.9874\n",
      "Epoch 97/100\n",
      "10000/10000 [==============================] - 1s 72us/sample - loss: 0.1209 - acc: 0.9867\n",
      "Epoch 98/100\n",
      "10000/10000 [==============================] - 1s 66us/sample - loss: 0.1208 - acc: 0.9874\n",
      "Epoch 99/100\n",
      "10000/10000 [==============================] - 1s 63us/sample - loss: 0.1136 - acc: 0.9878\n",
      "Epoch 100/100\n",
      "10000/10000 [==============================] - 1s 67us/sample - loss: 0.1195 - acc: 0.9862\n",
      "Training accuracy:0.9904999732971191\n",
      "Testing accuracy:0.34139999747276306\n",
      "Training accuracy:0.8023750185966492\n",
      "Validation accuracy:0.8023750185966492\n",
      "Testing accuracy:0.3610000014305115\n",
      "total time: 1295.0015001296997\n",
      "tr30000\n",
      "trial 0\n",
      "60000\n",
      "(5198,)\n",
      "(9802,)\n",
      "(4579,)\n",
      "(10421,)\n",
      "(7004,)\n",
      "(2996,)\n",
      "Epoch 1/100\n",
      "30000/30000 [==============================] - 3s 103us/sample - loss: 1.3205 - acc: 0.7498\n",
      "Epoch 2/100\n",
      "30000/30000 [==============================] - 2s 73us/sample - loss: 0.8924 - acc: 0.8099\n",
      "Epoch 3/100\n",
      "30000/30000 [==============================] - 2s 68us/sample - loss: 0.7237 - acc: 0.8221\n",
      "Epoch 4/100\n",
      "30000/30000 [==============================] - 2s 67us/sample - loss: 0.6335 - acc: 0.8267\n",
      "Epoch 5/100\n",
      "30000/30000 [==============================] - 2s 67us/sample - loss: 0.5733 - acc: 0.8352\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 2s 66us/sample - loss: 0.5340 - acc: 0.8389\n",
      "Epoch 7/100\n",
      "30000/30000 [==============================] - 2s 76us/sample - loss: 0.5044 - acc: 0.8418\n",
      "Epoch 8/100\n",
      "30000/30000 [==============================] - 2s 80us/sample - loss: 0.4777 - acc: 0.8474\n",
      "Epoch 9/100\n",
      "30000/30000 [==============================] - 2s 81us/sample - loss: 0.4588 - acc: 0.8488\n",
      "Epoch 10/100\n",
      "30000/30000 [==============================] - 2s 76us/sample - loss: 0.4394 - acc: 0.8541\n",
      "Epoch 11/100\n",
      "30000/30000 [==============================] - 2s 68us/sample - loss: 0.4213 - acc: 0.8615\n",
      "Epoch 12/100\n",
      "30000/30000 [==============================] - 2s 68us/sample - loss: 0.4094 - acc: 0.8645\n",
      "Epoch 13/100\n",
      "30000/30000 [==============================] - 2s 66us/sample - loss: 0.3965 - acc: 0.8683\n",
      "Epoch 14/100\n",
      "30000/30000 [==============================] - 2s 71us/sample - loss: 0.3831 - acc: 0.8745\n",
      "Epoch 15/100\n",
      "30000/30000 [==============================] - 2s 71us/sample - loss: 0.3718 - acc: 0.8789\n",
      "Epoch 16/100\n",
      "30000/30000 [==============================] - 2s 64us/sample - loss: 0.3625 - acc: 0.8837\n",
      "Epoch 17/100\n",
      "30000/30000 [==============================] - 2s 74us/sample - loss: 0.3490 - acc: 0.8885\n",
      "Epoch 18/100\n",
      "30000/30000 [==============================] - 2s 75us/sample - loss: 0.3410 - acc: 0.8949\n",
      "Epoch 19/100\n",
      "30000/30000 [==============================] - 2s 79us/sample - loss: 0.3221 - acc: 0.9016\n",
      "Epoch 20/100\n",
      "30000/30000 [==============================] - 2s 77us/sample - loss: 0.3223 - acc: 0.8986\n",
      "Epoch 21/100\n",
      "30000/30000 [==============================] - 2s 77us/sample - loss: 0.3056 - acc: 0.9101\n",
      "Epoch 22/100\n",
      "30000/30000 [==============================] - 2s 76us/sample - loss: 0.2979 - acc: 0.9119\n",
      "Epoch 23/100\n",
      "30000/30000 [==============================] - 2s 80us/sample - loss: 0.2930 - acc: 0.9140\n",
      "Epoch 24/100\n",
      "30000/30000 [==============================] - 2s 75us/sample - loss: 0.2862 - acc: 0.9184\n",
      "Epoch 25/100\n",
      "30000/30000 [==============================] - 2s 77us/sample - loss: 0.2789 - acc: 0.9207\n",
      "Epoch 26/100\n",
      "30000/30000 [==============================] - 2s 80us/sample - loss: 0.2683 - acc: 0.92560s - loss: 0.2679 - acc:\n",
      "Epoch 27/100\n",
      "30000/30000 [==============================] - 2s 75us/sample - loss: 0.2630 - acc: 0.9273\n",
      "Epoch 28/100\n",
      "30000/30000 [==============================] - 2s 76us/sample - loss: 0.2539 - acc: 0.9330\n",
      "Epoch 29/100\n",
      "30000/30000 [==============================] - 2s 75us/sample - loss: 0.2614 - acc: 0.9288\n",
      "Epoch 30/100\n",
      "30000/30000 [==============================] - 2s 76us/sample - loss: 0.2496 - acc: 0.9353\n",
      "Epoch 31/100\n",
      "30000/30000 [==============================] - 2s 72us/sample - loss: 0.2343 - acc: 0.9420\n",
      "Epoch 32/100\n",
      "30000/30000 [==============================] - 2s 74us/sample - loss: 0.2348 - acc: 0.9410\n",
      "Epoch 33/100\n",
      "30000/30000 [==============================] - 2s 76us/sample - loss: 0.2313 - acc: 0.9430\n",
      "Epoch 34/100\n",
      "30000/30000 [==============================] - 2s 80us/sample - loss: 0.2294 - acc: 0.9419\n",
      "Epoch 35/100\n",
      "30000/30000 [==============================] - 2s 78us/sample - loss: 0.2233 - acc: 0.9453\n",
      "Epoch 36/100\n",
      "30000/30000 [==============================] - 2s 74us/sample - loss: 0.2155 - acc: 0.9502\n",
      "Epoch 37/100\n",
      "30000/30000 [==============================] - 2s 78us/sample - loss: 0.2259 - acc: 0.9467\n",
      "Epoch 38/100\n",
      "30000/30000 [==============================] - 2s 79us/sample - loss: 0.2077 - acc: 0.9531\n",
      "Epoch 39/100\n",
      "30000/30000 [==============================] - 2s 77us/sample - loss: 0.2085 - acc: 0.9524\n",
      "Epoch 40/100\n",
      "30000/30000 [==============================] - 2s 77us/sample - loss: 0.2090 - acc: 0.9518\n",
      "Epoch 41/100\n",
      "30000/30000 [==============================] - 2s 74us/sample - loss: 0.2071 - acc: 0.9538\n",
      "Epoch 42/100\n",
      "30000/30000 [==============================] - 2s 79us/sample - loss: 0.2002 - acc: 0.9559\n",
      "Epoch 43/100\n",
      "30000/30000 [==============================] - 2s 74us/sample - loss: 0.2019 - acc: 0.9553\n",
      "Epoch 44/100\n",
      "30000/30000 [==============================] - 2s 79us/sample - loss: 0.1975 - acc: 0.9574\n",
      "Epoch 45/100\n",
      "30000/30000 [==============================] - 2s 76us/sample - loss: 0.1944 - acc: 0.9581\n",
      "Epoch 46/100\n",
      "30000/30000 [==============================] - 2s 81us/sample - loss: 0.1942 - acc: 0.9570\n",
      "Epoch 47/100\n",
      "30000/30000 [==============================] - 2s 79us/sample - loss: 0.1945 - acc: 0.9580\n",
      "Epoch 48/100\n",
      "30000/30000 [==============================] - 2s 75us/sample - loss: 0.1892 - acc: 0.9589\n",
      "Epoch 49/100\n",
      "30000/30000 [==============================] - 2s 75us/sample - loss: 0.1853 - acc: 0.9602\n",
      "Epoch 50/100\n",
      "30000/30000 [==============================] - 3s 84us/sample - loss: 0.1876 - acc: 0.9598\n",
      "Epoch 51/100\n",
      "30000/30000 [==============================] - 2s 81us/sample - loss: 0.1892 - acc: 0.9603\n",
      "Epoch 52/100\n",
      "30000/30000 [==============================] - 2s 80us/sample - loss: 0.1859 - acc: 0.9587\n",
      "Epoch 53/100\n",
      "30000/30000 [==============================] - 2s 83us/sample - loss: 0.1867 - acc: 0.9603\n",
      "Epoch 54/100\n",
      "30000/30000 [==============================] - 3s 86us/sample - loss: 0.1839 - acc: 0.9605\n",
      "Epoch 55/100\n",
      "30000/30000 [==============================] - 2s 81us/sample - loss: 0.1823 - acc: 0.9622\n",
      "Epoch 56/100\n",
      "30000/30000 [==============================] - 2s 83us/sample - loss: 0.1802 - acc: 0.9614\n",
      "Epoch 57/100\n",
      "30000/30000 [==============================] - 2s 78us/sample - loss: 0.1766 - acc: 0.9629\n",
      "Epoch 58/100\n",
      "30000/30000 [==============================] - 2s 80us/sample - loss: 0.1738 - acc: 0.9638\n",
      "Epoch 59/100\n",
      "30000/30000 [==============================] - 2s 78us/sample - loss: 0.1774 - acc: 0.9623\n",
      "Epoch 60/100\n",
      "30000/30000 [==============================] - 2s 73us/sample - loss: 0.1803 - acc: 0.9612\n",
      "Epoch 61/100\n",
      "30000/30000 [==============================] - 2s 81us/sample - loss: 0.1795 - acc: 0.9613\n",
      "Epoch 62/100\n",
      "30000/30000 [==============================] - 2s 76us/sample - loss: 0.1837 - acc: 0.9606\n",
      "Epoch 63/100\n",
      "30000/30000 [==============================] - 2s 76us/sample - loss: 0.1827 - acc: 0.9588\n",
      "Epoch 64/100\n",
      "30000/30000 [==============================] - 3s 84us/sample - loss: 0.1771 - acc: 0.9625\n",
      "Epoch 65/100\n",
      "30000/30000 [==============================] - 2s 79us/sample - loss: 0.1719 - acc: 0.9645\n",
      "Epoch 66/100\n",
      "30000/30000 [==============================] - 2s 81us/sample - loss: 0.1694 - acc: 0.9642\n",
      "Epoch 67/100\n",
      "30000/30000 [==============================] - 2s 80us/sample - loss: 0.1745 - acc: 0.9622\n",
      "Epoch 68/100\n",
      "30000/30000 [==============================] - 2s 81us/sample - loss: 0.1737 - acc: 0.9630\n",
      "Epoch 69/100\n",
      "30000/30000 [==============================] - 3s 85us/sample - loss: 0.1739 - acc: 0.9620\n",
      "Epoch 70/100\n",
      "30000/30000 [==============================] - 2s 79us/sample - loss: 0.1737 - acc: 0.96280s - loss: 0.1705 - ac\n",
      "Epoch 71/100\n",
      "30000/30000 [==============================] - 2s 80us/sample - loss: 0.1695 - acc: 0.9638\n",
      "Epoch 72/100\n",
      "30000/30000 [==============================] - 3s 85us/sample - loss: 0.1677 - acc: 0.9636\n",
      "Epoch 73/100\n",
      "30000/30000 [==============================] - 2s 82us/sample - loss: 0.1655 - acc: 0.9651\n",
      "Epoch 74/100\n",
      "30000/30000 [==============================] - 3s 87us/sample - loss: 0.1720 - acc: 0.9636\n",
      "Epoch 75/100\n",
      "30000/30000 [==============================] - 2s 80us/sample - loss: 0.1745 - acc: 0.9610\n",
      "Epoch 76/100\n",
      "30000/30000 [==============================] - 2s 83us/sample - loss: 0.1668 - acc: 0.9636\n",
      "Epoch 77/100\n",
      "30000/30000 [==============================] - 3s 84us/sample - loss: 0.1659 - acc: 0.9645\n",
      "Epoch 78/100\n",
      "30000/30000 [==============================] - 3s 93us/sample - loss: 0.1644 - acc: 0.9648\n",
      "Epoch 79/100\n",
      "30000/30000 [==============================] - 2s 82us/sample - loss: 0.1614 - acc: 0.9665\n",
      "Epoch 80/100\n",
      "30000/30000 [==============================] - 3s 84us/sample - loss: 0.1646 - acc: 0.9652\n",
      "Epoch 81/100\n",
      "30000/30000 [==============================] - 3s 84us/sample - loss: 0.1629 - acc: 0.9655\n",
      "Epoch 82/100\n",
      "30000/30000 [==============================] - 3s 86us/sample - loss: 0.1653 - acc: 0.96430s - loss: 0.1652 - acc: 0.96\n",
      "Epoch 83/100\n",
      "30000/30000 [==============================] - 2s 80us/sample - loss: 0.1632 - acc: 0.9654\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 3s 84us/sample - loss: 0.1663 - acc: 0.9644\n",
      "Epoch 85/100\n",
      "30000/30000 [==============================] - 2s 80us/sample - loss: 0.1619 - acc: 0.9649\n",
      "Epoch 86/100\n",
      "30000/30000 [==============================] - 2s 80us/sample - loss: 0.1608 - acc: 0.9657\n",
      "Epoch 87/100\n",
      "30000/30000 [==============================] - 2s 79us/sample - loss: 0.1621 - acc: 0.9653\n",
      "Epoch 88/100\n",
      "30000/30000 [==============================] - 2s 78us/sample - loss: 0.1646 - acc: 0.9649\n",
      "Epoch 89/100\n",
      "30000/30000 [==============================] - 2s 76us/sample - loss: 0.1670 - acc: 0.9632\n",
      "Epoch 90/100\n",
      "30000/30000 [==============================] - 2s 82us/sample - loss: 0.1603 - acc: 0.96621s - loss\n",
      "Epoch 91/100\n",
      "30000/30000 [==============================] - 2s 82us/sample - loss: 0.1574 - acc: 0.9668\n",
      "Epoch 92/100\n",
      "30000/30000 [==============================] - 2s 80us/sample - loss: 0.1609 - acc: 0.9649\n",
      "Epoch 93/100\n",
      "30000/30000 [==============================] - 2s 81us/sample - loss: 0.1589 - acc: 0.96471s - loss: 0.1\n",
      "Epoch 94/100\n",
      "30000/30000 [==============================] - 3s 86us/sample - loss: 0.1604 - acc: 0.9659\n",
      "Epoch 95/100\n",
      "30000/30000 [==============================] - 3s 94us/sample - loss: 0.1576 - acc: 0.9662\n",
      "Epoch 96/100\n",
      "30000/30000 [==============================] - 2s 79us/sample - loss: 0.1623 - acc: 0.9652\n",
      "Epoch 97/100\n",
      "30000/30000 [==============================] - 2s 82us/sample - loss: 0.1618 - acc: 0.9651\n",
      "Epoch 98/100\n",
      "30000/30000 [==============================] - 3s 87us/sample - loss: 0.1609 - acc: 0.9645\n",
      "Epoch 99/100\n",
      "30000/30000 [==============================] - 3s 84us/sample - loss: 0.1582 - acc: 0.9652\n",
      "Epoch 100/100\n",
      "30000/30000 [==============================] - 2s 79us/sample - loss: 0.1567 - acc: 0.96690s - loss: 0.1511 - ac\n",
      "Training accuracy:0.9717333316802979\n",
      "Testing accuracy:0.310699999332428\n",
      "Training accuracy:0.7210000157356262\n",
      "Validation accuracy:0.7210000157356262\n",
      "Testing accuracy:0.5092999935150146\n",
      "total time: 2246.1544859409332\n",
      "tr60000\n",
      "trial 0\n",
      "60000\n",
      "(10424,)\n",
      "(19576,)\n",
      "(9099,)\n",
      "(20901,)\n",
      "(6965,)\n",
      "(3035,)\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: 1.1356 - acc: 0.7689\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.7170 - acc: 0.8128\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 3s 50us/sample - loss: 0.5915 - acc: 0.8213\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 3s 50us/sample - loss: 0.5292 - acc: 0.8245\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.4895 - acc: 0.8266\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.4622 - acc: 0.8301\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.4427 - acc: 0.8321\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.4303 - acc: 0.8364\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.4195 - acc: 0.8367\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 0.4106 - acc: 0.8407\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.4037 - acc: 0.8423\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 0.3978 - acc: 0.8446\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 3s 51us/sample - loss: 0.3929 - acc: 0.8452\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 3s 51us/sample - loss: 0.3893 - acc: 0.8482\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.3843 - acc: 0.8515\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.3798 - acc: 0.8530\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.3785 - acc: 0.8537\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 0.3724 - acc: 0.8562\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.3700 - acc: 0.8592\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.3668 - acc: 0.8603\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.3639 - acc: 0.8602\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.3598 - acc: 0.8641\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.3532 - acc: 0.8678\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.3533 - acc: 0.8680\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 3s 50us/sample - loss: 0.3509 - acc: 0.8694\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 0.3454 - acc: 0.8726\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 3s 43us/sample - loss: 0.3418 - acc: 0.8739\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 2s 41us/sample - loss: 0.3405 - acc: 0.8729\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.3373 - acc: 0.8772\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.3324 - acc: 0.8776\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.3290 - acc: 0.8822\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.3277 - acc: 0.8826\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.3222 - acc: 0.8840\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.3201 - acc: 0.8844\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 0.3203 - acc: 0.8856\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 0.3157 - acc: 0.8870\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 0.3127 - acc: 0.8904\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 0.3114 - acc: 0.8904\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 0.3097 - acc: 0.8912\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.3045 - acc: 0.8949\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 0.2995 - acc: 0.8963\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 0.2996 - acc: 0.8976\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 0.2962 - acc: 0.8968\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 0.2956 - acc: 0.8989\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.2941 - acc: 0.9005\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 0.2896 - acc: 0.9003\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.2869 - acc: 0.9028\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 0.2876 - acc: 0.9027\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 0.2808 - acc: 0.9053\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 0.2819 - acc: 0.9043\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.2797 - acc: 0.9057\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 0.2773 - acc: 0.9072\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 0.2737 - acc: 0.9105\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 0.2757 - acc: 0.9079\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.2708 - acc: 0.9106\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.2719 - acc: 0.9112\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.2690 - acc: 0.9109\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.2701 - acc: 0.9112\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 4s 71us/sample - loss: 0.2642 - acc: 0.9132\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 0.2653 - acc: 0.9134\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 0.2649 - acc: 0.9133\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 0.2610 - acc: 0.9149\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: 0.2578 - acc: 0.9167\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 0.2603 - acc: 0.9154\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 0.2601 - acc: 0.9163\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 0.2607 - acc: 0.9157\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.2564 - acc: 0.9179\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.2534 - acc: 0.9178\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.2536 - acc: 0.9181\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.2491 - acc: 0.9212\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.2523 - acc: 0.9183\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 0.2514 - acc: 0.9199\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 0.2524 - acc: 0.9183\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.2480 - acc: 0.9219\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 0.2503 - acc: 0.9203\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 0.2497 - acc: 0.9203\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 0.2467 - acc: 0.9225\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 4s 72us/sample - loss: 0.2484 - acc: 0.9201\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.2466 - acc: 0.9211\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: 0.2435 - acc: 0.9232\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.2406 - acc: 0.9244\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 0.2414 - acc: 0.9260\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 0.2420 - acc: 0.9237\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 0.2439 - acc: 0.9230\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 0.2429 - acc: 0.9237\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.2388 - acc: 0.9256\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 4s 58us/sample - loss: 0.2420 - acc: 0.9245\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 0.2368 - acc: 0.9256\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.2385 - acc: 0.9248\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.2397 - acc: 0.9254\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 0.2378 - acc: 0.9250\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 0.2379 - acc: 0.9262\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 3s 58us/sample - loss: 0.2352 - acc: 0.9279\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 0.2345 - acc: 0.9269\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.2350 - acc: 0.9273\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.2336 - acc: 0.9279\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.2320 - acc: 0.9278\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 0.2362 - acc: 0.9280\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 0.2348 - acc: 0.9282\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.2334 - acc: 0.9282\n",
      "Training accuracy:0.940833330154419\n",
      "Testing accuracy:0.32679998874664307\n",
      "Training accuracy:0.699916660785675\n",
      "Validation accuracy:0.699916660785675\n",
      "Testing accuracy:0.5378000140190125\n",
      "total time: 2792.7786087989807\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_trial =10\n",
    "n_tr_list = [1000, 5000, 10000, 30000, 60000] # list of training sample sizes\n",
    "\n",
    "k=0\n",
    "K = len(n_tr_list)\n",
    "ERM_model_acc = np.zeros((K,n_trial))\n",
    "ERM_model_acc_nb = np.zeros((K,n_trial))\n",
    "IRM_model_acc = np.zeros((K,n_trial))\n",
    "IRM_model_acc_v = np.zeros((K,n_trial))\n",
    "\n",
    "ERM_model_acc1 = np.zeros((K,n_trial))\n",
    "ERM_model_acc1_nb = np.zeros((K,n_trial))\n",
    "IRM_model_acc1 = np.zeros((K,n_trial))\n",
    "IRM_model_acc1_v = np.zeros((K,n_trial))\n",
    "IRM_model_ind_v = np.zeros((K,n_trial))\n",
    "\n",
    "ERM_model_acc_av = np.zeros(K)\n",
    "ERM_model_acc_av_nb = np.zeros(K)\n",
    "IRM_model_acc_av = np.zeros(K)\n",
    "IRM_model_acc_av_v = np.zeros(K)\n",
    "\n",
    "\n",
    "ERM_model_acc_av1 = np.zeros(K)\n",
    "ERM_model_acc_av1_nb = np.zeros(K)\n",
    "IRM_model_acc_av1 = np.zeros(K)\n",
    "IRM_model_acc_av1_v = np.zeros(K)\n",
    "\n",
    "list_params = []\n",
    "for n_tr in n_tr_list:\n",
    "    print (\"tr\" + str(n_tr))\n",
    "#     print (\"start\")\n",
    "    t_start = time.time()\n",
    "    for trial in range(n_trial):\n",
    "        print (\"trial \" + str(trial))\n",
    "        n_e=2\n",
    "        p_color_list = [0.2, 0.1]\n",
    "        p_label_list = [0.25]*n_e\n",
    "        D = assemble_data_mnist_confounded(n_tr) # initialize confounded colored mnist digits data object\n",
    "\n",
    "        D.create_training_data(n_e, p_color_list, p_label_list) # creates the training environments\n",
    "\n",
    "        p_label_test = 0.25 # probability of switching pre-label in test environment\n",
    "        p_color_test = 0.9  # probability of switching the final label to obtain the color index in test environment\n",
    "\n",
    "        D.create_testing_data(p_color_test, p_label_test, n_e)  # sets up the testing environment\n",
    "        (num_examples_environment,length, width, height) = D.data_tuple_list[0][0].shape # attributes of the data\n",
    "        num_classes = len(np.unique(D.data_tuple_list[0][1])) # number of classes in the data\n",
    "\n",
    "        model_erm =  keras.Sequential([\n",
    "                keras.layers.Flatten(input_shape=(length,width,height)),\n",
    "                keras.layers.Dense(390, activation = 'relu',kernel_regularizer=keras.regularizers.l2(0.0011)),\n",
    "                keras.layers.Dense(390, activation='relu',kernel_regularizer=keras.regularizers.l2(0.0011)),\n",
    "                keras.layers.Dense(2, activation='softmax')\n",
    "        ])\n",
    "        \n",
    "        num_epochs = 100\n",
    "        batch_size = 512\n",
    "        learning_rate = 4.9e-4\n",
    "        erm_model1 = standard_erm_model(model_erm, num_epochs, batch_size, learning_rate)\n",
    "        erm_model1.fit(D.data_tuple_list)\n",
    "        erm_model1.evaluate(D.data_tuple_test)\n",
    "        print (\"Training accuracy:\" + str(erm_model1.train_acc))\n",
    "        print (\"Testing accuracy:\" + str(erm_model1.test_acc))\n",
    "        \n",
    "        ERM_model_acc[k][trial] = erm_model1.test_acc\n",
    "        ERM_model_acc1[k][trial] = erm_model1.train_acc\n",
    "\n",
    "\n",
    "        gamma_list = [10000, 33000, 66000,100000.0]\n",
    "        index=0\n",
    "        best_err = 1e6\n",
    "        train_list =[]\n",
    "        val_list = []\n",
    "        test_list = []\n",
    "        for gamma_new in gamma_list:\n",
    "\n",
    "            model_irm = keras.Sequential([\n",
    "                                keras.layers.Flatten(input_shape=(length,width,height)),\n",
    "                                keras.layers.Dense(390, activation = 'relu',kernel_regularizer=keras.regularizers.l2(0.0011)),\n",
    "                                keras.layers.Dense(390, activation='relu',kernel_regularizer=keras.regularizers.l2(0.0011)),\n",
    "                                keras.layers.Dense(num_classes)\n",
    "                        ])\n",
    "            batch_size       = 512\n",
    "            steps_max        = 1000\n",
    "            steps_threshold  = 190  ## threshold after which gamma_new is used\n",
    "            learning_rate    = 4.9e-4\n",
    "\n",
    "\n",
    "            irm_model1 = irm_model(model_irm, learning_rate, batch_size, steps_max, steps_threshold, gamma_new)\n",
    "            irm_model1.fit(D.data_tuple_list)\n",
    "            irm_model1.evaluate(D.data_tuple_test)\n",
    "            error_val = 1-irm_model1.val_acc\n",
    "            train_list.append(irm_model1.train_acc)\n",
    "            val_list.append(irm_model1.val_acc)\n",
    "            test_list.append(irm_model1.test_acc)\n",
    "            if(error_val<best_err):\n",
    "                index_best =index\n",
    "                best_err = error_val\n",
    "            index= index+1\n",
    "\n",
    "        print (\"Training accuracy:\" + str(train_list[index_best]))\n",
    "        print (\"Validation accuracy:\" + str(val_list[index_best]))\n",
    "        print (\"Testing accuracy:\" + str(test_list[index_best]))\n",
    "\n",
    "        IRM_model_acc_v[k][trial]  = test_list[index_best]\n",
    "        IRM_model_acc1_v[k][trial] = train_list[index_best]\n",
    "        IRM_model_ind_v[k][trial]  = index_best\n",
    "\n",
    "    IRM_model_acc_av_v[k] = np.mean(IRM_model_acc_v[k])\n",
    "    list_params.append([n_tr,\"IRMv_test\", np.mean(IRM_model_acc_v[k]),np.std(IRM_model_acc_v[k])])\n",
    "\n",
    "    ERM_model_acc_av[k] = np.mean(ERM_model_acc[k])\n",
    "    list_params.append([n_tr,\"ERM_test\", np.mean(ERM_model_acc[k]),np.std(ERM_model_acc[k])])\n",
    "\n",
    "\n",
    "    IRM_model_acc_av1_v[k] = np.mean(IRM_model_acc1_v[k])\n",
    "    list_params.append([n_tr,\"IRMv_train\", np.mean(IRM_model_acc1_v[k]),np.std(IRM_model_acc1_v[k])])\n",
    "    \n",
    "    ERM_model_acc_av1[k] = np.mean(ERM_model_acc1[k])\n",
    "    list_params.append([n_tr, \"ERM_train\", np.mean(ERM_model_acc1[k]),np.std(ERM_model_acc1[k])])\n",
    "\n",
    "    k=k+1\n",
    "\n",
    "    t_end = time.time()\n",
    "    print(\"total time: \" + str(t_end-t_start))\n",
    "\n",
    "ideal_error = np.ones(5)*0.25\n",
    "results = pd.DataFrame(list_params, columns= [\"Sample\",\"Method\", \"Performance\", \"Sdev\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.01, 0.8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.xlabel(\"Number of samples\", fontsize=16)\n",
    "plt.ylabel(\"Test error\", fontsize=16)\n",
    "plt.plot(n_tr_list, 1-ERM_model_acc_av, \"-r\", marker=\"+\", label=\"ERM\")\n",
    "plt.plot(n_tr_list, 1-IRM_model_acc_av_v, \"-b\", marker=\"s\",label=\"IRMv1\")\n",
    "plt.plot(n_tr_list, ideal_error, \"-g\", marker=\"x\", label=\"Optimal invariant\")\n",
    "plt.legend(loc=\"upper left\", fontsize=18)\n",
    "plt.ylim(-0.01,0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
